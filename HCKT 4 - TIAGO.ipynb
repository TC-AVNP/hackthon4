{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/book_review_labelled_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>rates_count</th>\n",
       "      <th>helpful_count</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3UPFTGAWZ3G2R</td>\n",
       "      <td>David J. Loftus</td>\n",
       "      <td>Jenkins, a history professor and Member of Par...</td>\n",
       "      <td>4</td>\n",
       "      <td>Quite readable, nicely done</td>\n",
       "      <td>12 6, 2001</td>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1XTKTLNSCRLDS</td>\n",
       "      <td>Ellen Rappaport</td>\n",
       "      <td>Detective Inspector Erlendur Sveinsson is at h...</td>\n",
       "      <td>5</td>\n",
       "      <td>Mesmerizing in depth</td>\n",
       "      <td>02 23, 2014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1A77B6DQQH436</td>\n",
       "      <td>crescamp \"esc\"</td>\n",
       "      <td>I didn't read this.  I purchased it for a gift...</td>\n",
       "      <td>3</td>\n",
       "      <td>10-minute life lessons for kids</td>\n",
       "      <td>02 12, 2013</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AEAF4MRYHJZI</td>\n",
       "      <td>Angelia Menchan \"acvermen.blogspot.com\"</td>\n",
       "      <td>Fierce Angels by Sheri Park reads like a disse...</td>\n",
       "      <td>4</td>\n",
       "      <td>So FIERCE</td>\n",
       "      <td>03 24, 2010</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A3B7KU72LGWFER</td>\n",
       "      <td>Grifel \"Tea Time\"</td>\n",
       "      <td>Clearly this author had two goals in mind: 1) ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Drivel!</td>\n",
       "      <td>06 21, 2003</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID                             reviewerName  \\\n",
       "0  A3UPFTGAWZ3G2R                          David J. Loftus   \n",
       "1  A1XTKTLNSCRLDS                          Ellen Rappaport   \n",
       "2  A1A77B6DQQH436                           crescamp \"esc\"   \n",
       "3    AEAF4MRYHJZI  Angelia Menchan \"acvermen.blogspot.com\"   \n",
       "4  A3B7KU72LGWFER                        Grifel \"Tea Time\"   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  Jenkins, a history professor and Member of Par...        4   \n",
       "1  Detective Inspector Erlendur Sveinsson is at h...        5   \n",
       "2  I didn't read this.  I purchased it for a gift...        3   \n",
       "3  Fierce Angels by Sheri Park reads like a disse...        4   \n",
       "4  Clearly this author had two goals in mind: 1) ...        1   \n",
       "\n",
       "                           summary   reviewTime  rates_count  helpful_count  \\\n",
       "0      Quite readable, nicely done   12 6, 2001           40             37   \n",
       "1             Mesmerizing in depth  02 23, 2014            0              0   \n",
       "2  10-minute life lessons for kids  02 12, 2013            3              0   \n",
       "3                        So FIERCE  03 24, 2010            9              9   \n",
       "4                          Drivel!  06 21, 2003           19             13   \n",
       "\n",
       "   rating  \n",
       "0       4  \n",
       "1       5  \n",
       "2       3  \n",
       "3       4  \n",
       "4       1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewerID       object\n",
       "reviewerName     object\n",
       "reviewText       object\n",
       "overall           int64\n",
       "summary          object\n",
       "reviewTime       object\n",
       "rates_count       int64\n",
       "helpful_count     int64\n",
       "rating            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/tiago/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import pandas as pd\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.base import TransformerMixin\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_tokenizer(data, tokenizer):\n",
    "    \"\"\"\n",
    "    Returns a list of strings that is the tokenization of the given data by applying the given tokenizer.\n",
    "    E.g. for an input [\"This is a test!\", \"No, it can't be\"],\n",
    "      it returns [\"This is a test !\", \"No , it can ' t be\"]\n",
    "    \n",
    "    Args:\n",
    "    data - list of strings containing the text to tokenize\n",
    "    tokenizer - nltk tokenizer\n",
    "    \"\"\"\n",
    "    #lista_tok = [\" \".join(WordPunctTokenizer().tokenize(x)) for x in data]\n",
    "    lista_tok = [\" \".join(tokenizer.tokenize(x)) for x in data]\n",
    "    #teste = WordPunctTokenizer().tokenize(data[1])\n",
    "    \n",
    "    #print(lista_tok[:2])\n",
    "    return lista_tok\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_lowercase(data):\n",
    "    \"\"\"\n",
    "    Returns a list of strings, with all the tokens lowercased.\n",
    "    \n",
    "    Args:\n",
    "    data - list of strings to be lowercased\n",
    "    \"\"\"\n",
    "    #print(data[1])\n",
    "    list_lower = [x.lower() for x in data]\n",
    "    #print(list_lower[1])\n",
    "    return list_lower\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_list = stopwords.words('english')\n",
    "def apply_filter_stopwords(data, stopword_list):\n",
    "    \"\"\"\n",
    "    Returns a list of strings, where the strings do not contain any of\n",
    "        the stopwords in the given list.\n",
    "    \n",
    "    Args:\n",
    "    data - list of strings to filter stopwords from\n",
    "    stopword_list - list of stopwords to filter out\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filter the stopwords from the text\n",
    "    data_no_stopwords = []\n",
    "    for x in data:\n",
    "        aux = \" \".join([w for w in x.split() if w not in stopword_list])\n",
    "        data_no_stopwords.append(aux)\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()\n",
    "    return data_no_stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_filter_punct(data):\n",
    "    \"\"\"\n",
    "    Returns a list of strings, with no punctuation.\n",
    "    \n",
    "    Args:\n",
    "    data - list of strings from which to remove punctuation\n",
    "    \"\"\"\n",
    "\n",
    "    data_no_punct = []\n",
    "    for x in data:\n",
    "        \n",
    "        aux = \"\".join([w for w in x if w not in string.punctuation])\n",
    "        data_no_punct.append(aux)\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()\n",
    "    return data_no_punct\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_whitespace(data):\n",
    "    return [re.sub(r\"^\\s+|\\s+$|(?<=\\s)\\s*\", \"\", text) for text in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_stemmer(data, stemmer):\n",
    "    \"\"\"\n",
    "    Returns a list of strings, with stemmed data.\n",
    "    \n",
    "    Args:\n",
    "    data - list with text to stem\n",
    "    stemmer - instance of stemmer to use\n",
    "    \"\"\"\n",
    "    \n",
    "    list_tok = [WordPunctTokenizer().tokenize(x) for x in data]\n",
    "    stems = [\" \".join(list(map(stemmer.stem, y))) for y in list_tok]\n",
    "    return stems\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCleanerTransformer(TransformerMixin):\n",
    "    def __init__(self, tokenizer, lower=True, remove_punct=True, stopwords=[], stemmer=None):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.stemmer = stemmer\n",
    "        self.lower = lower\n",
    "        self.remove_punct = remove_punct\n",
    "        self.stopwords = stopwords\n",
    "    \n",
    "    def clean_sentences(self, data):\n",
    "                \n",
    "        # Split sentence into list of words\n",
    "        sentences_preprocessed = apply_tokenizer(data, self.tokenizer)\n",
    "        # YOUR CODE HERE\n",
    "        #raise NotImplementedError()\n",
    "        \n",
    "        # Lowercase\n",
    "        if self.lower:\n",
    "            sentences_preprocessed = apply_lowercase(sentences_preprocessed)\n",
    "            # YOUR CODE HERE\n",
    "            #raise NotImplementedError()\n",
    "\n",
    "        if self.stopwords:\n",
    "            sentences_preprocessed = apply_filter_stopwords(sentences_preprocessed,self.stopwords)\n",
    "            # YOUR CODE HERE\n",
    "            #raise NotImplementedError()\n",
    "            \n",
    "        # Remove punctuation\n",
    "        if self.remove_punct:\n",
    "            sentences_preprocessed = apply_filter_punct(sentences_preprocessed)\n",
    "            # YOUR CODE HERE\n",
    "            #raise NotImplementedError()\n",
    "        \n",
    "        # Normalize whitespace\n",
    "        sentences_preprocessed = normalize_whitespace(sentences_preprocessed)\n",
    "        # YOUR CODE HERE\n",
    "        #raise NotImplementedError()\n",
    "    \n",
    "        # Stem words\n",
    "        if self.stemmer:\n",
    "            sentences_preprocessed = apply_stemmer(sentences_preprocessed,self.stemmer)\n",
    "            # YOUR CODE HERE\n",
    "            #raise NotImplementedError()\n",
    "\n",
    "        return sentences_preprocessed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cleaner = TextCleanerTransformer(\n",
    "    WordPunctTokenizer(),\n",
    "    lower=True, \n",
    "    remove_punct=True, \n",
    "    stopwords=stopwords.words('english'),\n",
    "    stemmer=SnowballStemmer(\"english\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pre = text_cleaner.clean_sentences(df_train['reviewText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pre_summ = text_cleaner.clean_sentences(df_train['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jenkin histori professor member parliament well author acclaim bio gladston present fine biographi britain greatest 20th centuri figur experi uniqu qualifi describ churchil polit fortun maneuv although american reader may find teen twenti either slow go suffici illumin britain odd polit system wherein politician regular shop around district repres even defeat anoth fair tradit public polit bio psychoanalysi impli churchil much person life expos move along surpris good clip despit 900 plus page jenkin fulli remind us churchil basic earn live writer contract write schedul royalti care record though polit avoc author write clean engag though seem inordin fond unnecessarili unusu word like quot psepholog quot quot rumbusti quot hand wit dri regular evid u hardcov edit farrar straus amp giroux clean halfway point whereupon one begin encount quot feburari quot 436 quot repli hard everi allow quot 553 quot shore quot 706 quot dimay quot 721 quot opposit could chose relax quot 837 8 similar infel jenkin seem strike nice balanc healthi respect subject clear eye churchil weak chang direct occasion seizur dishonesti well illustr 90 b amp w photo', 'detect inspector erlendur sveinsson best uncov multi layer case newli discov skeleton skeleton got locat slope grafarholt hill mysteri solv person buri profession opinion age skeleton erlendur call nation museum submit name archaeologist skarphedinn elinborg sigurdur oli work erlendur investig histori interview resid area past present mysteri skeleton begin unravel tale sorrow behind tale true stori teller could put ink tale involv past secret kept hidden reason known experienc sorrow time brought anoth unsolv mysteri regard miss girl girl engag marri short believ thrown sea reason behind action yet discov appear sister will particip investig erlendur go perhap one worst trial life daughter eva lind good result latest travesti novel miss prepar dear reader mesmer skill writer content chapter winner covet golden dagger award present british crime writer associ']\n"
     ]
    }
   ],
   "source": [
    "print(X_train_pre[:2])f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['quit readabl nice done', 'mesmer depth']\n"
     ]
    }
   ],
   "source": [
    "print(X_train_pre_summ[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ABRIR PASTA FISICA DO ARQUIVO\n",
    "!explorer.exe ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
