{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d4709c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sys import executable, argv\n",
    "from subprocess import check_output\n",
    "# import pctils as pc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sys import executable, argv\n",
    "from subprocess import check_output\n",
    "# import pctils as pc\n",
    "# SKLearn related imports\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import spacy\n",
    "import hashlib\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from spacy.matcher import Matcher\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c922bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>rates_count</th>\n",
       "      <th>helpful_count</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3UPFTGAWZ3G2R</td>\n",
       "      <td>David J. Loftus</td>\n",
       "      <td>Jenkins, a history professor and Member of Par...</td>\n",
       "      <td>4</td>\n",
       "      <td>Quite readable, nicely done</td>\n",
       "      <td>12 6, 2001</td>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1XTKTLNSCRLDS</td>\n",
       "      <td>Ellen Rappaport</td>\n",
       "      <td>Detective Inspector Erlendur Sveinsson is at h...</td>\n",
       "      <td>5</td>\n",
       "      <td>Mesmerizing in depth</td>\n",
       "      <td>02 23, 2014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1A77B6DQQH436</td>\n",
       "      <td>crescamp \"esc\"</td>\n",
       "      <td>I didn't read this.  I purchased it for a gift...</td>\n",
       "      <td>3</td>\n",
       "      <td>10-minute life lessons for kids</td>\n",
       "      <td>02 12, 2013</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID     reviewerName  \\\n",
       "0  A3UPFTGAWZ3G2R  David J. Loftus   \n",
       "1  A1XTKTLNSCRLDS  Ellen Rappaport   \n",
       "2  A1A77B6DQQH436   crescamp \"esc\"   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  Jenkins, a history professor and Member of Par...        4   \n",
       "1  Detective Inspector Erlendur Sveinsson is at h...        5   \n",
       "2  I didn't read this.  I purchased it for a gift...        3   \n",
       "\n",
       "                           summary   reviewTime  rates_count  helpful_count  \\\n",
       "0      Quite readable, nicely done   12 6, 2001           40             37   \n",
       "1             Mesmerizing in depth  02 23, 2014            0              0   \n",
       "2  10-minute life lessons for kids  02 12, 2013            3              0   \n",
       "\n",
       "   rating  \n",
       "0       4  \n",
       "1       5  \n",
       "2       3  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = pd.read_csv('data/book_review_labelled_data.csv')[0:3]\n",
    "dummy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a617e0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_docs = dummy.reviewText\n",
    "text_docs[0]\n",
    "tk = WordPunctTokenizer() \n",
    "def tkze(tk,text_docs): \n",
    "    return [\" \".join(tk.tokenize(doc)) for doc in text_docs]\n",
    "\n",
    "docs = tkze(tk,text_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06a57698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of words \n",
    "def get_nb_words(docs): \n",
    "    return ([len(doc.split()) for doc in docs])\n",
    "\n",
    "# get_nb_words(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd64e445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average word size \n",
    "def get_av_word_size(docs):\n",
    "    av_words_size_per_doc = [] \n",
    "    for doc in docs: \n",
    "        words_size = [len(word) for word in doc.split()]\n",
    "        av_size = np.mean(np.array(words_size))\n",
    "        av_words_size_per_doc.append(av_size)\n",
    "    return av_words_size_per_doc\n",
    "# get_av_word_size(docs)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cfa50802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1652892561983471, 0.15625, 0.8571428571428571]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of unique words (proxy for how rich is the reviewer vocabulary)\n",
    "# not really sure if this feature will be useful (maybe couple with PoS) \n",
    "def get_nb_unique_words(docs):\n",
    "    unique_words = [len(set(word for word in doc)) for doc in docs] \n",
    "    normalized = (np.array(unique_words)/np.array(get_nb_words(docs))).tolist()\n",
    "    return normalized\n",
    "# get_nb_unique_words(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24f22e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# important for spacy related functions\n",
    "# nlp = spacy.load('en_core_web_sm')\n",
    "# nlp_docs = list(tqdm(nlp.pipe(docs), total=len(docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b9accda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting NERs (proxy for attention to detail by reviewers that describe book parts, e.g. naming book charters)\n",
    "def get_most_common_persons(nlp_docs, n_most_common=10): \n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    pattern = [[{'ENT_TYPE':'PERSON'}]]\n",
    "    matcher.add('ppl', pattern)\n",
    "\n",
    "    persons = []\n",
    "    for doc in nlp_docs: \n",
    "        matches = matcher(doc)\n",
    "        for match_id, start, end in matches: \n",
    "            persons.append(str(doc[start:end]))\n",
    "\n",
    "    most_common_ents = [person for person in Counter(persons).most_common()[:n_most_common]]\n",
    "    return most_common_ents\n",
    "\n",
    "# get_most_common_persons(nlp_docs)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d806117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[115, 98, 11]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of predefined parts of speech \n",
    "def get_nb_PoS(nlp_docs): # docs tokenized string  \n",
    "    PoS_list = ['ADJ','NOUN','VERB'] \n",
    "    nb_PoS = [] \n",
    "    for doc in nlp_docs: \n",
    "        total_PoS = [token.pos_ for token in doc if token.pos_ in PoS_list]  \n",
    "        nb_in_doc = sum([Counter(total_PoS)[x] for x in PoS_list])\n",
    "        nb_PoS.append(nb_in_doc)\n",
    "    return nb_PoS\n",
    "\n",
    "# get_nb_PoS(nlp_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8727b0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_nb_unique_PoS(nlp_docs): # docs tokenized string  \n",
    "    PoS_list = ['ADJ','NOUN'] \n",
    "    nb_unique_PoS = [] \n",
    "    nb_PoS = []\n",
    "    word4PoS = [] \n",
    "    for doc in nlp_docs: \n",
    "        total_PoS = [token.pos_ for token in doc]\n",
    "        mask = np.array([True if PoS in PoS_list else False for PoS in total_PoS])\n",
    "        # print(mask[:10])\n",
    "        words = np.array([token.text for token in doc])\n",
    "        words_under_selected_PoS = words[mask].tolist()\n",
    "        word4PoS.append(words_under_selected_PoS)\n",
    "        # print(words_under_selected_PoS)\n",
    "        unique_words = get_nb_unique_words(words_under_selected_PoS)\n",
    "        nb_unique_PoS.append(len(unique_words))\n",
    "        nb_PoS.append(len(words_under_selected_PoS))\n",
    "        \n",
    "    ratio = np.array(nb_unique_PoS)/ np.array(nb_PoS)\n",
    "    return ratio.tolist(), word4PoS\n",
    "    \n",
    "# get_nb_unique_PoS(nlp_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a664764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_extra_features(df, docs, nlp_docs): \n",
    "    df[\"nb_words\"] = pd.Series(get_nb_words(docs)) \n",
    "    df[\"av_word_size\"] = pd.Series(get_av_word_size(docs))\n",
    "    df[\"nb_unique_words\"] = pd.Series(get_nb_unique_words(docs)) # not work properly \n",
    "    \n",
    "    \n",
    "    # get_most_common_persons(nlp_docs, n_most_common=10) \n",
    "    \n",
    "    df[\"nb_PoS\"] = pd.Series(get_nb_PoS(nlp_docs))\n",
    "    df[\"nb_unique_PoS\"] = pd.Series(get_nb_unique_PoS(nlp_docs)[0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42c7c691",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 35.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>rates_count</th>\n",
       "      <th>helpful_count</th>\n",
       "      <th>rating</th>\n",
       "      <th>nb_words</th>\n",
       "      <th>av_word_size</th>\n",
       "      <th>nb_unique_words</th>\n",
       "      <th>nb_PoS</th>\n",
       "      <th>nb_unique_PoS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3UPFTGAWZ3G2R</td>\n",
       "      <td>David J. Loftus</td>\n",
       "      <td>Jenkins, a history professor and Member of Par...</td>\n",
       "      <td>4</td>\n",
       "      <td>Quite readable, nicely done</td>\n",
       "      <td>12 6, 2001</td>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>363</td>\n",
       "      <td>4.223140</td>\n",
       "      <td>0.165289</td>\n",
       "      <td>115</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1XTKTLNSCRLDS</td>\n",
       "      <td>Ellen Rappaport</td>\n",
       "      <td>Detective Inspector Erlendur Sveinsson is at h...</td>\n",
       "      <td>5</td>\n",
       "      <td>Mesmerizing in depth</td>\n",
       "      <td>02 23, 2014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>288</td>\n",
       "      <td>4.399306</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>98</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1A77B6DQQH436</td>\n",
       "      <td>crescamp \"esc\"</td>\n",
       "      <td>I didn't read this.  I purchased it for a gift...</td>\n",
       "      <td>3</td>\n",
       "      <td>10-minute life lessons for kids</td>\n",
       "      <td>02 12, 2013</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID     reviewerName  \\\n",
       "0  A3UPFTGAWZ3G2R  David J. Loftus   \n",
       "1  A1XTKTLNSCRLDS  Ellen Rappaport   \n",
       "2  A1A77B6DQQH436   crescamp \"esc\"   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  Jenkins, a history professor and Member of Par...        4   \n",
       "1  Detective Inspector Erlendur Sveinsson is at h...        5   \n",
       "2  I didn't read this.  I purchased it for a gift...        3   \n",
       "\n",
       "                           summary   reviewTime  rates_count  helpful_count  \\\n",
       "0      Quite readable, nicely done   12 6, 2001           40             37   \n",
       "1             Mesmerizing in depth  02 23, 2014            0              0   \n",
       "2  10-minute life lessons for kids  02 12, 2013            3              0   \n",
       "\n",
       "   rating  nb_words  av_word_size  nb_unique_words  nb_PoS  nb_unique_PoS  \n",
       "0       4       363      4.223140         0.165289     115            1.0  \n",
       "1       5       288      4.399306         0.156250      98            1.0  \n",
       "2       3        28      3.285714         0.857143      11            1.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dummy.copy() \n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp_docs = list(tqdm(nlp.pipe(docs), total=len(docs)))\n",
    "add_extra_features(df, docs, nlp_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e01ccf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!explorer.exe .\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
